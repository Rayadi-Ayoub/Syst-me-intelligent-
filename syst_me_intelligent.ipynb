{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPZEWSd2AD3qvIJClL9Kzls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rayadi-Ayoub/Syst-me-intelligent-/blob/main/syst_me_intelligent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyPGiE3HZqIj",
        "outputId": "c68eddd6-b1e3-406b-a0bd-57f843fcb280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "yjyNM_YOaYHf",
        "outputId": "f85011a8-6c9c-4a8f-e941-a4dc017073ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'files' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4221232239.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installe le package 'kaggle' depuis PyPI\n",
        "# Ce package permet d'interagir avec l'API Kaggle (t√©l√©chargement de datasets, participation √† des comp√©titions, etc.)\n",
        "!pip install kaggle\n",
        "\n",
        "# Importe le module 'files' de Google Colab\n",
        "# Ce module permet d'importer ou exporter des fichiers entre ton ordinateur et l'environnement Colab\n",
        "from google.colab import files\n",
        "\n",
        "# Ouvre une bo√Æte de dialogue pour importer le fichier kaggle.json\n",
        "# Ce fichier contient tes identifiants d'API Kaggle (username et key)\n",
        "files.upload()\n",
        "\n",
        "# Cr√©e un dossier cach√© nomm√© '.kaggle' dans le r√©pertoire personnel (~)\n",
        "# Ce dossier sert √† stocker le fichier de configuration d'acc√®s √† l'API Kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# D√©place le fichier 'kaggle.json' t√©l√©charg√© vers le dossier '.kaggle'\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "\n",
        "# Change les permissions du fichier 'kaggle.json'\n",
        "# Le chiffre 600 signifie : seul le propri√©taire du fichier peut le lire et l'√©crire\n",
        "# (c‚Äôest une mesure de s√©curit√© exig√©e par l‚ÄôAPI Kaggle)\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n"
      ],
      "metadata": {
        "id": "RYeXevuz1X0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"simhadrisadaram/mimic-cxr-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "S6ULl1CN1gBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# D√©finit le chemin de base (base_path) vers le dossier local o√π est stock√© le dataset t√©l√©charg√© depuis Kaggle.\n",
        "# Ici, le chemin pointe vers le cache interne de KaggleHub, utilis√© par Colab pour stocker les datasets Kaggle.\n",
        "# Le dossier correspond au dataset \"mimic-cxr-dataset\" de l‚Äôutilisateur \"simhadrisadaram\", version 2.\n",
        "base_path = \"/root/.cache/kagglehub/datasets/simhadrisadaram/mimic-cxr-dataset/versions/2\"\n"
      ],
      "metadata": {
        "id": "dcTuz6Hh1aOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "base_path = \"/root/.cache/kagglehub/datasets/simhadrisadaram/mimic-cxr-dataset/versions/2\"\n",
        "\n",
        "# V√©rifie l'existence des fichiers\n",
        "print(\"Contenu du dossier :\", os.listdir(base_path))\n",
        "\n",
        "train_csv = os.path.join(base_path, \"mimic_cxr_aug_train.csv\")\n",
        "val_csv = os.path.join(base_path, \"mimic_cxr_aug_validate.csv\")\n",
        "\n",
        "# V√©rifie si les fichiers existent avant lecture\n",
        "if not os.path.exists(train_csv):\n",
        "    raise FileNotFoundError(f\"Fichier d'entra√Ænement introuvable : {train_csv}\")\n",
        "if not os.path.exists(val_csv):\n",
        "    raise FileNotFoundError(f\"Fichier de validation introuvable : {val_csv}\")\n",
        "\n",
        "df_train = pd.read_csv(train_csv)\n",
        "df_val = pd.read_csv(val_csv)\n",
        "\n",
        "print(\"Train shape:\", df_train.shape)\n",
        "print(\"Validation shape:\", df_val.shape)\n",
        "df_train.head()\n"
      ],
      "metadata": {
        "id": "ilUOPgWz1lMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast  # pour convertir la cha√Æne en liste Python\n",
        "\n",
        "def extract_image_path(path_str):\n",
        "    try:\n",
        "        path_list = ast.literal_eval(path_str)\n",
        "        if isinstance(path_list, list) and len(path_list) > 0:\n",
        "            return path_list[0]  # on garde le premier chemin\n",
        "        else:\n",
        "            return None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "df_train['image_path'] = df_train['image'].apply(extract_image_path)\n",
        "df_val['image_path'] = df_val['image'].apply(extract_image_path)\n",
        "\n",
        "print(df_train[['subject_id', 'image_path', 'view']].head())\n"
      ],
      "metadata": {
        "id": "Oqqoy-ah1w4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importe le module 'ast' (Abstract Syntax Trees)\n",
        "# Ce module permet de convertir une cha√Æne de caract√®res repr√©sentant une structure Python (ex: liste, dict)\n",
        "# en un v√©ritable objet Python de mani√®re s√©curis√©e (contrairement √† eval()).\n",
        "import ast\n",
        "\n",
        "# D√©finition d'une fonction pour v√©rifier si une image a une vue frontale (PA ou AP)\n",
        "def has_frontal_view(views_str):\n",
        "    try:\n",
        "        # Convertit la cha√Æne 'views_str' (par ex. \"['PA', 'LATERAL']\") en une vraie liste Python\n",
        "        views = ast.literal_eval(views_str)\n",
        "\n",
        "        # V√©rifie si au moins un des √©l√©ments de la liste est 'PA' (Posteroanterior) ou 'AP' (Anteroposterior)\n",
        "        # Ces deux types correspondent √† des vues frontales de radiographies thoraciques\n",
        "        return any(v in ['PA', 'AP'] for v in views)\n",
        "\n",
        "    except:\n",
        "        # En cas d'erreur (par exemple si la cha√Æne est vide ou mal form√©e), renvoie False\n",
        "        return False\n",
        "\n",
        "# Filtre le DataFrame d'entra√Ænement pour ne garder que les lignes ayant une vue frontale\n",
        "# La m√©thode .apply() applique la fonction 'has_frontal_view' √† chaque valeur de la colonne 'view'\n",
        "df_frontal = df_train[df_train['view'].apply(has_frontal_view)].copy()\n",
        "\n",
        "# Affiche le nombre d‚Äôimages frontales par rapport au total du dataset d'entra√Ænement\n",
        "print(\"Images frontales :\", len(df_frontal), \"/\", len(df_train))\n",
        "\n",
        "# Affiche les 3 premi√®res lignes du DataFrame filtr√© pour v√©rification\n",
        "df_frontal.head(3)\n"
      ],
      "metadata": {
        "id": "gWkn5j6612Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation du module 'os' : permet d‚Äôinteragir avec le syst√®me d‚Äôexploitation\n",
        "# (ex : naviguer dans les dossiers, construire des chemins de fichiers, lister des r√©pertoires, etc.)\n",
        "import os\n",
        "\n",
        "# Importation d'OpenCV (cv2) : une biblioth√®que tr√®s utilis√©e pour le traitement d'images et la vision par ordinateur\n",
        "# Elle permet de lire, redimensionner, convertir et transformer les images.\n",
        "import cv2\n",
        "\n",
        "# Importation de NumPy : utilis√©e pour manipuler efficacement des tableaux num√©riques multidimensionnels\n",
        "# (par ex. les matrices repr√©sentant des images)\n",
        "import numpy as np\n",
        "\n",
        "# Importation de Matplotlib : utilis√©e pour la visualisation (affichage d'images, trac√©s, histogrammes, etc.)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importation de tqdm : affiche une barre de progression lors des boucles, tr√®s pratique pour suivre l‚Äôavancement du traitement de nombreuses images\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Importation de TensorFlow : framework de deep learning pour construire, entra√Æner et ex√©cuter des mod√®les neuronaux\n",
        "import tensorflow as tf\n",
        "\n",
        "# Importation de la fonction 'img_to_array' de Keras (module inclus dans TensorFlow)\n",
        "# Elle permet de convertir une image PIL (ou un tableau OpenCV) en tableau NumPy adapt√© aux mod√®les de deep learning\n",
        "from tensorflow.keras.utils import img_to_array\n"
      ],
      "metadata": {
        "id": "1P3xOLEQ13Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# D√©finit la taille standard √† laquelle les images seront redimensionn√©es\n",
        "# (224x224 pixels) ‚Äî c‚Äôest une taille courante pour les mod√®les de deep learning\n",
        "# tels que ResNet, VGG, DenseNet, etc.\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# D√©finit le chemin de base o√π sont stock√©es les images du dataset MIMIC-CXR\n",
        "# Ce r√©pertoire contient les images officielles utilis√©es pour l‚Äôentra√Ænement et la validation\n",
        "base_images = \"/root/.cache/kagglehub/datasets/simhadrisadaram/mimic-cxr-dataset/versions/2/official_data_iccv_final\"\n",
        "\n",
        "# D√©finition d'une fonction utilitaire pour obtenir le chemin absolu complet d'une image\n",
        "def full_image_path(rel_path):\n",
        "    # Remplace \"files/\" par une cha√Æne vide si pr√©sent dans le chemin relatif\n",
        "    # Cela permet d‚Äô√©viter les doublons dans le chemin (par ex. '.../official_data_iccv_final/files/...').\n",
        "    # Ensuite, on assemble ce chemin corrig√© avec 'base_images' gr√¢ce √† os.path.join()\n",
        "    return os.path.join(base_images, rel_path.replace(\"files/\", \"\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "-wpkVjj-15nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction de chargement et de pr√©traitement d'une image\n",
        "def load_and_preprocess_image(path):\n",
        "    # 1Ô∏è‚É£ Lecture de l'image √† partir du chemin sp√©cifi√©\n",
        "    # 'cv2.IMREAD_GRAYSCALE' convertit l'image en niveaux de gris (1 canal)\n",
        "    # Les radiographies (comme celles du dataset MIMIC-CXR) sont en noir et blanc,\n",
        "    # donc cette option r√©duit la complexit√© sans perte d'information utile.\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 2Ô∏è‚É£ Redimensionnement de l'image √† la taille standard d√©finie (224x224)\n",
        "    # Cela garantit une taille d'entr√©e uniforme pour le r√©seau de neurones\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "    # 3Ô∏è‚É£ Normalisation des valeurs de pixels entre 0 et 1\n",
        "    # Les valeurs d'origine (0‚Äì255) sont divis√©es par 255.0\n",
        "    # La normalisation acc√©l√®re et stabilise l'entra√Ænement du mod√®le\n",
        "    img = img / 255.0  # normalisation 0-1\n",
        "\n",
        "    # 4Ô∏è‚É£ Ajout d'une dimension suppl√©mentaire pour le canal (grayscale ‚Üí 1 canal)\n",
        "    # La nouvelle forme devient (224, 224, 1), conforme aux attentes de TensorFlow/Keras\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "    # 5Ô∏è‚É£ Retourne l'image pr√©trait√©e\n",
        "    return img\n",
        "\n"
      ],
      "metadata": {
        "id": "jsjc0YZK17zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation du module 'os' :\n",
        "# Permet d‚Äôinteragir avec le syst√®me d‚Äôexploitation, notamment pour g√©rer les chemins de fichiers,\n",
        "# cr√©er des dossiers ou lister les fichiers dans un r√©pertoire.\n",
        "import os\n",
        "\n",
        "# Importation de la biblioth√®que OpenCV (cv2) :\n",
        "# Utilis√©e pour le traitement d'images : lecture, redimensionnement, conversion de couleurs, filtrage, etc.\n",
        "import cv2\n",
        "\n",
        "# Importation de NumPy :\n",
        "# Fournit des structures de donn√©es performantes pour manipuler des tableaux num√©riques (matrices, tenseurs),\n",
        "# tr√®s utilis√©es pour repr√©senter les images et effectuer des op√©rations math√©matiques rapides.\n",
        "import numpy as np\n",
        "\n",
        "# Importation de Pandas :\n",
        "# Permet de manipuler facilement les donn√©es tabulaires (comme les CSV) sous forme de DataFrames,\n",
        "# pour organiser les m√©tadonn√©es associ√©es aux images (ex. chemins, labels, etc.)\n",
        "import pandas as pd\n",
        "\n",
        "# Importation de Matplotlib :\n",
        "# Biblioth√®que de visualisation, utilis√©e pour afficher des images, des courbes d'entra√Ænement, etc.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importation de tqdm :\n",
        "# Ajoute des barres de progression dans les boucles (for, map...) pour suivre visuellement l‚Äôavancement du traitement\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Importation des modules de Keras (int√©gr√© √† TensorFlow) :\n",
        "# 'layers' permet de cr√©er les diff√©rentes couches du r√©seau de neurones (Conv2D, Dense, Dropout, etc.)\n",
        "# 'models' permet de construire, compiler et entra√Æner le mod√®le de deep learning\n",
        "from tensorflow.keras import layers, models\n"
      ],
      "metadata": {
        "id": "OushTQ2D1-lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# D√©finit le chemin de base vers le dossier du dataset MIMIC-CXR t√©l√©charg√© via Kaggle\n",
        "# Ce dossier contient les fichiers CSV et les sous-dossiers d‚Äôimages.\n",
        "base_path = \"/root/.cache/kagglehub/datasets/simhadrisadaram/mimic-cxr-dataset/versions/2\"\n",
        "\n",
        "# Construit le chemin complet vers le dossier contenant les images officielles du dataset\n",
        "# \"official_data_iccv_final\" est le sous-dossier o√π se trouvent les fichiers d'images radiographiques.\n",
        "img_root = os.path.join(base_path, \"official_data_iccv_final\")\n",
        "\n",
        "# Charge le fichier CSV d'entra√Ænement du dataset MIMIC-CXR dans un DataFrame Pandas.\n",
        "# Ce fichier contient g√©n√©ralement :\n",
        "# - les chemins relatifs des images (ex: \"files/patient12345/image1.png\")\n",
        "# - les m√©tadonn√©es (vue, sexe, √¢ge, etc.)\n",
        "# - et les √©tiquettes associ√©es aux maladies ou anomalies d√©tect√©es.\n",
        "df = pd.read_csv(os.path.join(base_path, \"mimic_cxr_aug_train.csv\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "ZNf2_xzp2A7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation du module 'ast' (Abstract Syntax Trees)\n",
        "# Ce module permet de convertir en toute s√©curit√© une cha√Æne repr√©sentant une structure Python\n",
        "# (ex. \"['PA', 'LATERAL']\") en un objet Python r√©el (liste, dictionnaire, etc.)\n",
        "import ast\n",
        "\n",
        "\n",
        "# D√©finition d'une fonction utilitaire pour v√©rifier si une radiographie est une vue frontale\n",
        "def has_frontal_view(views_str):\n",
        "    try:\n",
        "        # Convertit la cha√Æne de texte (ex: \"['PA', 'LATERAL']\") en liste Python\n",
        "        views = ast.literal_eval(views_str)\n",
        "\n",
        "        # V√©rifie si la liste contient une vue frontale :\n",
        "        # 'PA' (Posteroanterior) ou 'AP' (Anteroposterior)\n",
        "        # Ces deux types de vues repr√©sentent les radiographies prises de face\n",
        "        return any(v in ['PA', 'AP'] for v in views)\n",
        "\n",
        "    except:\n",
        "        # Si la conversion √©choue (ex : valeur manquante ou format invalide),\n",
        "        # la fonction renvoie False pour ignorer cette ligne\n",
        "        return False\n",
        "\n",
        "\n",
        "# Filtrage du DataFrame pour ne garder que les radiographies frontales\n",
        "# On applique la fonction 'has_frontal_view' √† la colonne 'view'\n",
        "# et on cr√©e une copie du sous-ensemble correspondant\n",
        "df_frontal = df[df['view'].apply(has_frontal_view)].copy()\n",
        "\n",
        "\n",
        "# Extraction du chemin relatif de l‚Äôimage\n",
        "# La colonne 'image' contient une cha√Æne repr√©sentant une liste (ex : \"['files/patient123/image1.png']\")\n",
        "# On utilise 'ast.literal_eval' pour en extraire le premier √©l√©ment (le vrai chemin de l'image)\n",
        "df_frontal['image_path'] = df_frontal['image'].apply(\n",
        "    lambda x: ast.literal_eval(x)[0] if isinstance(x, str) else None\n",
        ")\n",
        "\n",
        "\n",
        "# Construction du chemin absolu complet vers chaque image\n",
        "# On combine le chemin racine 'img_root' avec le chemin relatif extrait ci-dessus\n",
        "# On retire le pr√©fixe \"files/\" pour √©viter les doublons dans le chemin\n",
        "df_frontal['full_path'] = df_frontal['image_path'].apply(\n",
        "    lambda p: os.path.join(img_root, p.replace(\"files/\", \"\")) if p else None\n",
        ")\n",
        "\n",
        "\n",
        "# Affiche le nombre total d‚Äôimages frontales d√©tect√©es\n",
        "print(\" Images frontales :\", len(df_frontal))\n",
        "\n",
        "# Affiche les premi√®res lignes du DataFrame avec les identifiants patients et chemins d‚Äôacc√®s complets\n",
        "print(df_frontal[['subject_id', 'full_path']].head())\n"
      ],
      "metadata": {
        "id": "pWHkoIKS2C8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# D√©finition d'une fonction qui construit un mod√®le U-Net pour la segmentation d'images\n",
        "def unet_model(input_size=(224, 224, 1)):\n",
        "    # Couche d'entr√©e ‚Äî attend des images de taille 224x224 avec 1 canal (niveaux de gris)\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # ===============================\n",
        "    #  ENCODER (Partie contractante)\n",
        "    # ===============================\n",
        "\n",
        "    # Bloc 1 ‚Äî Premi√®re couche de convolution\n",
        "    c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D()(c1)  # R√©duction de la taille (downsampling)\n",
        "\n",
        "    # Bloc 2\n",
        "    c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D()(c2)\n",
        "\n",
        "    # Bloc 3\n",
        "    c3 = layers.Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, 3, activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D()(c3)\n",
        "\n",
        "    # ===============================\n",
        "    #  BOTTLENECK (partie centrale)\n",
        "    # ===============================\n",
        "    # Partie la plus profonde du r√©seau : capture les caract√©ristiques les plus abstraites\n",
        "    c4 = layers.Conv2D(512, 3, activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(512, 3, activation='relu', padding='same')(c4)\n",
        "\n",
        "    # ===============================\n",
        "    #  DECODER (Partie expansive)\n",
        "    # ===============================\n",
        "\n",
        "    # Bloc 4 ‚Äî Upsampling + concat√©nation avec la couche correspondante du chemin descendant (skip connection)\n",
        "    u5 = layers.UpSampling2D()(c4)\n",
        "    u5 = layers.concatenate([u5, c3])\n",
        "    c5 = layers.Conv2D(256, 3, activation='relu', padding='same')(u5)\n",
        "    c5 = layers.Conv2D(256, 3, activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Bloc 5\n",
        "    u6 = layers.UpSampling2D()(c5)\n",
        "    u6 = layers.concatenate([u6, c2])\n",
        "    c6 = layers.Conv2D(128, 3, activation='relu', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(128, 3, activation='relu', padding='same')(c6)\n",
        "\n",
        "    # Bloc 6\n",
        "    u7 = layers.UpSampling2D()(c6)\n",
        "    u7 = layers.concatenate([u7, c1])\n",
        "    c7 = layers.Conv2D(64, 3, activation='relu', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(64, 3, activation='relu', padding='same')(c7)\n",
        "\n",
        "    # ===============================\n",
        "    # Sortie finale\n",
        "    # ===============================\n",
        "\n",
        "    # Couche de sortie : 1 canal de sortie (masque binaire)\n",
        "    # Activation sigmo√Øde ‚Üí valeurs entre 0 et 1 pour la segmentation binaire\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c7)\n",
        "\n",
        "    # Cr√©ation du mod√®le complet\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "# ===============================\n",
        "#  Compilation et r√©sum√© du mod√®le\n",
        "# ===============================\n",
        "\n",
        "# Cr√©ation de l‚Äôinstance du mod√®le\n",
        "unet = unet_model()\n",
        "\n",
        "# Compilation du mod√®le :\n",
        "# - Optimiseur Adam (efficace pour la segmentation)\n",
        "# - Fonction de perte binaire (car masque 0/1)\n",
        "unet.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Affiche la structure compl√®te du mod√®le U-Net\n",
        "unet.summary()\n"
      ],
      "metadata": {
        "id": "3qgsHk7G2IMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# D√©finition de la taille standard des images\n",
        "# Les radiographies seront redimensionn√©es √† 224x224 pixels pour √™tre compatibles avec le mod√®le U-Net\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "\n",
        "# Fonction de pr√©traitement et de segmentation d‚Äôune image\n",
        "def preprocess_and_segment(image_path):\n",
        "    # Lecture de l'image en niveaux de gris\n",
        "    # cv2.IMREAD_GRAYSCALE permet de r√©duire les images √† un seul canal (utile pour les radiographies)\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # V√©rifie que l'image a bien √©t√© charg√©e (√©vite les erreurs si le fichier est manquant ou corrompu)\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    #  Redimensionnement de l'image √† la taille standard (224x224)\n",
        "    img = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "    #  Normalisation des valeurs de pixels entre 0 et 1 (am√©liore la stabilit√© du mod√®le)\n",
        "    img_norm = img / 255.0\n",
        "\n",
        "    #  Ajout de dimensions suppl√©mentaires :\n",
        "    # - La premi√®re (axis=0) correspond au batch (1 image)\n",
        "    # - La derni√®re (axis=-1) correspond au canal (grayscale ‚Üí 1)\n",
        "    # Forme finale : (1, 224, 224, 1)\n",
        "    inp = np.expand_dims(img_norm, axis=(0, -1))\n",
        "\n",
        "    #  Pr√©diction du masque de segmentation √† partir du mod√®le U-Net entra√Æn√©\n",
        "    # 'verbose=0' √©vite les messages de progression √† chaque pr√©diction\n",
        "    mask = unet.predict(inp, verbose=0)[0, :, :, 0]\n",
        "\n",
        "    #  Seuillage du masque : on garde les valeurs sup√©rieures √† 0.5 (probabilit√© > 50%)\n",
        "    # Cela cr√©e un masque binaire (0 ou 1)\n",
        "    mask = (mask > 0.5).astype(np.uint8)\n",
        "\n",
        "    #  Application du masque sur l'image originale\n",
        "    # Les zones non segment√©es (0) deviennent noires, les zones d√©tect√©es sont conserv√©es\n",
        "    img_masked = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "    #  Normalisation de la sortie pour un affichage facile (valeurs 0‚Äì1)\n",
        "    return img_masked / 255.0\n",
        "\n",
        "\n",
        "# ===============================\n",
        "#  Application sur un ensemble d'images\n",
        "# ===============================\n",
        "\n",
        "X_preprocessed = []  # liste pour stocker les images segment√©es\n",
        "\n",
        "# R√©cup√©ration de la liste compl√®te des chemins des images frontales\n",
        "paths = df_frontal['full_path'].tolist()\n",
        "\n",
        "# Boucle sur un √©chantillon des 200 premi√®res images pour tester le pipeline\n",
        "for path in tqdm(paths[:200]):  # tqdm affiche une barre de progression\n",
        "    # V√©rifie que le fichier existe\n",
        "    if os.path.exists(path):\n",
        "        # Pr√©traite et segmente l'image\n",
        "        img = preprocess_and_segment(path)\n",
        "        # Ajoute l'image segment√©e si elle a bien √©t√© trait√©e\n",
        "        if img is not None:\n",
        "            X_preprocessed.append(img)\n",
        "\n",
        "# Conversion de la liste en tableau NumPy (forme : nombre_images √ó 224 √ó 224)\n",
        "X_preprocessed = np.array(X_preprocessed)\n",
        "\n",
        "# Affiche la taille finale du jeu de donn√©es segment√©\n",
        "print(\"Donn√©es pr√™tes :\", X_preprocessed.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "eNRHx6h22NxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affiche le premier chemin complet d‚Äôimage contenu dans le DataFrame df_frontal\n",
        "# Cela permet de v√©rifier que les chemins ont bien √©t√© construits lors des √©tapes pr√©c√©dentes\n",
        "print(\"Exemple de chemin :\", df_frontal['full_path'].iloc[0])\n",
        "\n",
        "# V√©rifie si le fichier correspondant √† ce chemin existe r√©ellement sur le disque\n",
        "# os.path.exists() renvoie True si le fichier est trouv√©, sinon False\n",
        "print(\"Existe :\", os.path.exists(df_frontal['full_path'].iloc[0]))\n",
        "\n"
      ],
      "metadata": {
        "id": "5WEIbf_z2X7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/root/.cache/kagglehub/datasets/simhadrisadaram/mimic-cxr-dataset/versions/2/official_data_iccv_final/files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg\""
      ],
      "metadata": {
        "id": "KrkdTSdH2Z0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation des biblioth√®ques n√©cessaires\n",
        "# 'os' ‚Üí permet de v√©rifier l'existence des fichiers et manipuler les chemins\n",
        "# 'cv2' ‚Üí utilis√© pour lire et traiter les images (OpenCV)\n",
        "# 'matplotlib.pyplot' ‚Üí sert √† afficher les images et graphiques\n",
        "import os, cv2, matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# V√©rifie si le fichier image existe √† l'emplacement indiqu√© par la variable 'path'\n",
        "# Cela √©vite les erreurs en cas de chemin incorrect ou de fichier manquant\n",
        "print(\"Existe :\", os.path.exists(path))\n",
        "\n",
        "\n",
        "# Lecture de l'image en niveaux de gris (grayscale)\n",
        "# cv2.IMREAD_GRAYSCALE charge l‚Äôimage avec un seul canal (valeurs 0‚Äì255)\n",
        "# Utile pour les radiographies, qui sont d√©j√† monochromes\n",
        "img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "# Affichage de l'image avec Matplotlib\n",
        "# cmap='gray' ‚Üí indique √† Matplotlib d‚Äôutiliser une √©chelle de gris\n",
        "plt.imshow(img, cmap='gray')\n",
        "\n",
        "# Supprime les axes (graduations, √©tiquettes) pour un affichage plus propre\n",
        "plt.axis('off')\n",
        "\n",
        "# Affiche effectivement l‚Äôimage dans le notebook\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "bWLiNEHj2bk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_root = \"/root/.cache/kagglehub/datasets/simhadrisadaram/mimic-cxr-dataset/versions/2/official_data_iccv_final\"\n",
        "\n",
        "df_frontal['full_path'] = df_frontal['image_path'].apply(\n",
        "    lambda p: os.path.join(img_root, \"files\", p.split(\"files/\")[-1]) if isinstance(p, str) else None\n",
        ")\n",
        "\n",
        "# V√©rification\n",
        "sample_path = df_frontal['full_path'].iloc[0]\n",
        "print(\" Exemple de chemin :\", sample_path)\n",
        "print(\"Existe :\", os.path.exists(sample_path))\n"
      ],
      "metadata": {
        "id": "nMR4R0SJ2dp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation des biblioth√®ques n√©cessaires\n",
        "import matplotlib.pyplot as plt   # Pour afficher les images\n",
        "import cv2                        # Pour lire les fichiers image (OpenCV)\n",
        "import os                         # Pour v√©rifier l‚Äôexistence des fichiers et manipuler les chemins\n",
        "\n",
        "\n",
        "# üîç S√©lection des chemins d'images valides\n",
        "# On parcourt la colonne 'full_path' du DataFrame, en supprimant les valeurs manquantes (NaN)\n",
        "# et on garde uniquement les chemins dont le fichier existe r√©ellement sur le disque\n",
        "valid_paths = [p for p in df_frontal['full_path'].dropna().tolist() if os.path.exists(p)]\n",
        "\n",
        "# On s√©lectionne les deux premi√®res images valides pour l‚Äôaffichage\n",
        "samples = valid_paths[:2]\n",
        "\n",
        "\n",
        "# üñºÔ∏è Cr√©ation d‚Äôune figure Matplotlib pour afficher les images c√¥te √† c√¥te\n",
        "plt.figure(figsize=(8, 4))  # Taille totale de la figure (largeur x hauteur en pouces)\n",
        "\n",
        "# Boucle sur les images s√©lectionn√©es\n",
        "for i, path in enumerate(samples):\n",
        "    # Lecture de l'image en niveaux de gris (1 canal)\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # V√©rification : si l‚Äôimage n‚Äôa pas pu √™tre charg√©e, on passe √† la suivante\n",
        "    if img is None:\n",
        "        print(f\"‚ö†Ô∏è Impossible de lire : {path}\")\n",
        "        continue\n",
        "\n",
        "    # Cr√©ation d‚Äôun sous-graphique pour chaque image\n",
        "    plt.subplot(1, 2, i + 1)  # 1 ligne, 2 colonnes, position i+1\n",
        "\n",
        "    # Affichage de l‚Äôimage avec une √©chelle de gris\n",
        "    plt.imshow(img, cmap='gray')\n",
        "\n",
        "    # Ajout d‚Äôun titre indiquant le num√©ro et le nom du fichier image\n",
        "    plt.title(f\"Image {i+1}\\n{os.path.basename(path)}\")\n",
        "\n",
        "    # Suppression des axes pour un affichage plus propre\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "# Ajuste automatiquement la disposition pour √©viter que les images ou titres se chevauchent\n",
        "plt.tight_layout()\n",
        "\n",
        "# Affiche les images dans le notebook\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "nhTvDYSG2gxl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}